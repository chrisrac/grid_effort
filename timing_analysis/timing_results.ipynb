{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05fb3e33-baa7-45f0-b439-04727c1f21e5",
   "metadata": {},
   "source": [
    "# HEX timing analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427ecf8d-c623-4b15-b798-ae871dd4eb7c",
   "metadata": {},
   "source": [
    "performed on timing_script.ipynb <br>\n",
    "<b>no parallelization</b> <br>\n",
    "<br>\n",
    "Processor: Intel(R) Xeon(R) w3-2435 3.10 GHz 16 core <br>\n",
    "RAM: 64.0 GB"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5104962d-922d-43e3-8a45-ab8d7f6a5467",
   "metadata": {},
   "source": [
    "### Reading in\n",
    "![alt text](timing_1.png \"Hex data read in time\") <br>\n",
    "Performance is highly dependant on the data location. Using local drive significantly speeds up the process. <br>\n",
    "Generally, reading data from K drive constitutes to about 90% of total execution time. <br>\n",
    "<br>\n",
    "Reading file by file seems to save little time, but could improve mmory management, if cleaned accordingly <br>\n",
    "<br>\n",
    "Tab. Data reading in time (in seconds) <br>\n",
    "|   | H5 |\tH6 | H7 | H8 | H9 |\n",
    "|-:|:-:|:-:|:-:|:-:|:-:|\n",
    "|K: drive (partial) |0.542\t| 13.7\t| 88\t| 615\t| dropped |\n",
    "|local drive (partial) |0.148\t| 0.717\t| 4.68\t| 33\t| 230 |\n",
    "|local drive (full) |0.679\t| 4.24\t| 28.5\t| 198\t| 1391 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "720fd447-d43c-4a87-b9df-0913fbf2acf9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Spatial join \n",
    "![alt text](timing_3.png \"Hex data read in time\") <br>\n",
    "Timing for spatial join depends on the size of data used and hex resolution. <br>\n",
    "H5 can perform all operation in under a minute, and this time increases with the number of hexes, up to 4.5h on H9. One solution would be batching hexes, or perallelizing the code. <br>\n",
    "When about 1/5 in size hex layer is joined to H5 or H6 procedure it takes couple seconds, and increases with hex resolution, up to roughly 28 minutes for H9. <br>\n",
    "If performed in batches, merge time needs to be included. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f12dce-ea29-4e30-9202-934db38d7368",
   "metadata": {},
   "source": [
    "### Writing data to geodatabase\n",
    "![alt text](timing_4.png \"\") <br>\n",
    "Depending on the size, writing data into geodatabase file takes up to 25 minutes at H9."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b8cfa2b-b1f7-4ee7-8c05-1884bf39084d",
   "metadata": {},
   "source": [
    "### Final full execution time\n",
    "<br>\n",
    "Tab. Execution timing, this includes reading data in (local drive), process spatial joins of all five layers (no parallelization) and saving data into geodatabase\n",
    "\n",
    "|| H5 | H6 | H7 | H8 | H9 |\n",
    "|-:|:-:|:-:|:-:|:-:|:-:|\n",
    "|full data, in minutes|0.810|1.584|8.078|48.26|325.2 (5h 25min)|\n",
    "|partial data, in minutes|0.194|0.257|1.376|5.698|36.66|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d9c32f-ef8e-47a2-a2ba-e10ef39e869d",
   "metadata": {},
   "source": [
    "### Data size\n",
    "<br>\n",
    "Tab. Size of finalized data (local drive) in geodatabase format, all five layers joined\n",
    "\n",
    "|| H5 | H6 | H7 | H8 | H9 |\n",
    "|-:|:-:|:-:|:-:|:-:|:-:|\n",
    "|data size|57.8 MB|47.5 MB|117 MB|519 MB|2.97 GB|\n",
    "\n",
    "<br>\n",
    "No type manipulation and cleaning yet implemented <br>\n",
    "\n",
    "![alt text](timing_5.png \" \")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac862fe-bd0d-4a6a-a5b2-e83ed1f74e2d",
   "metadata": {},
   "source": [
    "### Identified issues\n",
    "\n",
    "- no parallelization / batching\n",
    "- data cleaning (null, missing data)\n",
    "- format transformation (string, int)\n",
    "- h10 is too big for 64GB memory and requires either slicing or HPC to run\n", 
    "- possible different join predicates (center, within...) [full list here](https://shapely.readthedocs.io/en/latest/manual.html#binary-predicates)\n",
    "![alt text](timing_6.png \" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b87ebd6-f0c5-4f4c-854f-279b0efd0704",
   "metadata": {},
   "source": [
    "### Code example, h5, all layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94d4ddd-4f36-4627-8776-a22cf3cf0233",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import fiona\n",
    "\n",
    "# Define the path to the geodatabases used\n",
    "hex_gdb = r\"C://Research/Grid_effort/H3_5_10_Grd.gdb\"\n",
    "inputs_gdb = r'C://Research/Grid_effort/H3Grid_Inputs.gdb'\n",
    "\n",
    "# Hex level\n",
    "hexLevel = '5'\n",
    "\n",
    "# Read in the Hex polygon grid layer as the base layer\n",
    "base_layer = gpd.read_file(hex_gdb, layer='H3_'+hexLevel)\n",
    "base_layer.drop(columns=['Shape_Length','Shape_Area'],inplace=True)\n",
    "\n",
    "# Read all joined layers from geodatabase\n",
    "layers_to_join = ['tj_2021_us_st_cnt', 'Estuarine_Drainage_Areas', 'WBDHU8', 'dtl_cnty_Census_ESRI', 'WBDHU12']\n",
    "layer_gdfs = {layer: gpd.read_file(inputs_gdb, layer=layer) for layer in layers_to_join}\n",
    "\n",
    "# Spatial join\n",
    "for name, gdf in layer_gdfs.items():\n",
    "    # Ensure the CRS is the same between the base layer and the current layer\n",
    "    if not gdf.crs == base_layer.crs:\n",
    "        gdf = gdf.to_crs(base_layer.crs)\n",
    "    if 'Shape_Length' in gdf.columns:\n",
    "        gdf.drop('Shape_Length', axis=1, inplace=True)\n",
    "    if 'Shape_Area' in gdf.columns:\n",
    "        gdf.drop('Shape_Area', axis=1, inplace=True)\n",
    "\n",
    "    # Perform spatial join (inner join by default)\n",
    "    base_layer = gpd.sjoin(base_layer, gdf, how=\"left\")\n",
    "    \n",
    "    # Drop the `index_right` column if it exists\n",
    "    if 'index_right' in base_layer.columns:\n",
    "        base_layer.drop('index_right', axis=1, inplace=True)\n",
    "\n",
    "# Save the output\n",
    "base_layer.to_file('h'+hexLevel+'_allAtOnce.gdb',driver='OpenFileGDB')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
