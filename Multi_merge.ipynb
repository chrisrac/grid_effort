{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a10f0fb5-a44c-4808-b60a-c21fa26572f3",
   "metadata": {},
   "source": [
    "# Multi-layer merge script"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "706491e6-ab7c-415e-985f-6763c1e1c4d0",
   "metadata": {},
   "source": [
    "This script runs a single layer join on hex grid. Uses Kate's generated hexes and Inputs.<br>\n",
    "There is no cleaning and type controll. No optimization/vectorization/parallelization. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92e8045d-5626-41c4-9008-72a4dd488d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules\n",
    "import geopandas as gpd\n",
    "import fiona"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e725d74-8b72-4ca1-9c37-ae328b5d1990",
   "metadata": {},
   "source": [
    "Modify below cell to indicate path to database, hex level and joined layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27fd48d1-303b-47ce-88b6-38f72424ff79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define path to hex grid database\n",
    "hex_gdb = r'C://Research/Grid_effort/H3_5_10_Grd.gdb'\n",
    "# Define hex level\n",
    "hexLevel = '5'\n",
    "\n",
    "# Define the path to the geodatabase with joined layer\n",
    "inputs_gdb = r'C://Research/Grid_effort/H3Grid_Inputs.gdb'\n",
    "# Names of layers to join in the list, determines the order of joins\n",
    "layers_to_join = ['tj_2021_us_st_cnt', 'Estuarine_Drainage_Areas', 'WBDHU8', 'dtl_cnty_Census_ESRI', 'WBDHU12']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baff9224-facc-4a5e-af8e-19473ee6fef4",
   "metadata": {},
   "source": [
    "Run below cell to perform merge and save result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5183460-cb6a-4ff3-ad48-89e5eed85795",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the hex polygon grid layer as the base layer\n",
    "base_layer = gpd.read_file(hex_gdb, layer='H3_'+hexLevel)\n",
    "base_layer.drop(columns=['Shape_Length','Shape_Area'],inplace=True)\n",
    "# Read the joined layers into dictionary\n",
    "layer_gdfs = {layer: gpd.read_file(inputs_gdb, layer=layer) for layer in layers_to_join}\n",
    "# Check if garbage data is present and try to remove it\n",
    "for name, gdf in layer_gdfs.items():\n",
    "    # Ensure the CRS is the same between the base layer and the current layer\n",
    "    if not gdf.crs == base_layer.crs:\n",
    "        gdf = gdf.to_crs(base_layer.crs)\n",
    "    # Check if garbage data is present and remove it\n",
    "    if 'Shape_Length' in gdf.columns:\n",
    "        gdf.drop('Shape_Length', axis=1, inplace=True)\n",
    "    if 'Shape_Area' in gdf.columns:\n",
    "        gdf.drop('Shape_Area', axis=1, inplace=True)\n",
    "    # Perform spatial join\n",
    "    # here a modification migh be needed, to include different predicates parameter, to differ results\n",
    "    # more here: https://shapely.readthedocs.io/en/latest/manual.html#binary-predicates\n",
    "    base_layer = gpd.sjoin(base_layer, gdf, how=\"left\")\n",
    "    # Drop the `index_right` column if it exists\n",
    "    if 'index_right' in base_layer.columns:\n",
    "        base_layer.drop('index_right', axis=1, inplace=True)\n",
    "# Save the result in work path\n",
    "base_layer.to_file('h'+hexLevel+'_multipleMerges.gdb',driver='OpenFileGDB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a4dff9d-f4a0-481e-8df2-c991da1043b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
